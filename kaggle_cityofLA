#https://business.linkedin.com/talent-solutions/blog/job-descriptions/2018/5-must-dos-for-writing-inclusive-job-descriptions
#http://people.cs.uchicago.edu/~ravenben/publications/pdf/gender-cscw18.pdf
options(warn = -1); options(scipen = 999)
#======================================================
#dir <- '../input/cityofla//CityofLA//'
dir <- "CityofLA/"
#dir <- "D:/OneDrive - CGIAR/Documents/kaggle/CityofLA/"
bulletin_folder <- "Job Bulletins/"
#======================================================
# Required libraries, load yourselves!
pkgs <- c("tidyverse", "tidytext", "tm", "tokenizers", "rword2vec", "readr")
for (pkg in pkgs) {
  if (! (pkg %in% rownames(installed.packages()))){install.packages(pkg)}
  library(pkg, character.only = TRUE)
}
rm(pkgs, pkg)

# if (!require(wordVectors)) {
#   if (!(require(devtools))) {
#     install.packages("devtools")
#   }
#   devtools::install_github("bmschmidt/wordVectors")
# }
# library(wordVectors)
gc()
#======================================================
# Define functions
# Bulletin lines getter
get_bulletinLines <- function(file_name, dir, quietly = F){
  if(!quietly){print(file_name)}
  bulletin_lines <- readLines(paste0(dir, file_name))
  bulletin_lines <- as.character(unlist(bulletin_lines))
  bulletin_lines <- str_trim(bulletin_lines)
  ind_rm <- which(bulletin_lines == "")
  if(length(ind_rm) != 0){
    bulletin_lines <- bulletin_lines[-ind_rm]
    
  }
  return(bulletin_lines)
}

get_jobTitle_fromBulletin <- function(bulletin_lines, gsub_pattern){
  #------------------------------
  # This snippet required since some job titles appear on second line
  # of bulletin, with "CAMPUS INTERVIEWS ONLY" taking the first line.
  jobTitle_line <- ifelse(length(grep("CAMPUS INTERVIEWS ONLY", bulletin_lines[1])) == 0,
                          bulletin_lines[1], bulletin_lines[2])
  # The snippet can be removed if job title always appears on first line of bulletin.
  #------------------------------
  str <- gsub(gsub_pattern, "", jobTitle_line)
  jobTitle_from_bulletin <- str_trim(str)
  return(jobTitle_from_bulletin)
}


get_openDate <- function(bulletin_lines, gsub_pattern = "\\b[^0-9-]"){
  ind_openDate <- grep("Open Date", bulletin_lines, ignore.case = T)
  xx <- bulletin_lines[ind_openDate[1]]
  open_date <- gsub(gsub_pattern, "", xx)
  #if(nchar(open_date) > 8){open_date <- substr(open_date, 5, 12)} #"MARINE ENVIRONMENTAL SUPERVISOR" "SENIOR COMPUTER OPERATOR 1428 102017.txt" "SUPERVISING CRIMINALIST 2235 030416.txt" 
  return(open_date)
}



# Job class number from bulletin getter function
get_jobClassNum_fromBulletin <- function(bulletin_lines){
  ind_line <- grep("\\d{4}", bulletin_lines[1:3])
  if(length(ind_line) != 0){
    ind_line <- ind_line[1]
    job_class_num <- gsub(".*(\\d{4}).*", "\\1", bulletin_lines[ind_line])
    jobClassNum_from_bulletin <- str_trim(job_class_num)
  }else{
    jobClassNum_from_bulletin <- NA
  }
  return(jobClassNum_from_bulletin)
}




# Bulletin section headings getter
get_sectionHeadings <- function(bulletin_lines,
                                grep_pattern = "^[A-Z :/,\t\\(\\)]+$"){
  ind_headings <- grep(grep_pattern, bulletin_lines)
  section_headings <- bulletin_lines[ind_headings]
  section_headings <- str_trim(section_headings)
  return(section_headings)
}

# Section text getter
get_sectionTxt <- function(section_name, bulletin_lines, section_headings){
  ind_section_start <- grep(section_name, bulletin_lines) + 1
  if(length(ind_section_start) != 0){
    str_section_end <- section_headings[grep(section_name, section_headings) + 1]
    ind_section_end <- grep(str_section_end, bulletin_lines) - 1
    ind_rm <- which(ind_section_end < ind_section_start)
    if(length(ind_rm) != 0){
      ind_section_end <- ind_section_end[-ind_rm]
    }
    ind_section_end <- ind_section_end[1]
    str_section <- bulletin_lines[ind_section_start:ind_section_end]
    str_section <- paste(str_section, collapse = " ")
  }else{
    str_section <- ""
  }
}

# Convert written numbers to digits
convert_writNum_to_digits <- function(writNum){
  oneToTen <- "(one|two|three|four|five|six|seven|eight|nine|ten)"
  if(length(grep(oneToTen, writNum, ignore.case = T)) != 0){
    if(length(grep("one", writNum, ignore.case = T)) != 0){digitNum <- gsub("one", "1", writNum, ignore.case = T)}
    if(length(grep("two", writNum, ignore.case = T)) != 0){digitNum <- gsub("two", "2", writNum, ignore.case = T)}
    if(length(grep("three", writNum, ignore.case = T)) != 0){digitNum <- gsub("three", "3", writNum, ignore.case = T)}
    if(length(grep("four", writNum, ignore.case = T)) != 0){digitNum <- gsub("four", "4", writNum, ignore.case = T)}
    if(length(grep("five", writNum, ignore.case = T)) != 0){digitNum <- gsub("five", "5", writNum, ignore.case = T)}
    if(length(grep("six", writNum, ignore.case = T)) != 0){digitNum <- gsub("six", "6", writNum, ignore.case = T)}
    if(length(grep("seven", writNum, ignore.case = T)) != 0){digitNum <- gsub("seven", "7", writNum, ignore.case = T)}
    if(length(grep("eight", writNum, ignore.case = T)) != 0){digitNum <- gsub("eight", "8", writNum, ignore.case = T)}
    if(length(grep("nine", writNum, ignore.case = T)) != 0){digitNum <- gsub("nine", "9", writNum, ignore.case = T)}
    if(length(grep("ten", writNum, ignore.case = T)) != 0){digitNum <- gsub("ten", "10", writNum, ignore.case = T)}
    out <- digitNum
    
  }else{
    out <- NA
  }
  return(out)
}


# Get required experience job title
get_expJobClassTitle <- function(experience_requirement, pattern_jobTitle, pattern_jobTitle_trimPunct, stopWords){
  xx_jobTitle <- gsub(pattern_jobTitle, "\\2", experience_requirement, ignore.case = T)
  if(length(xx_jobTitle) != 0){
    if(!is.na(xx_jobTitle)){
      if(nchar(xx_jobTitle) > 70){
        exp_job_class_title <- NA
      }else{
        # Trim commas etc. from required experience job title
        xx_jobTitle <- gsub(pattern_jobTitle_trimPunct, "\\1", xx_jobTitle, ignore.case = T)
        # Trim stop words from required experience job title
        xx_jobTitle <- unlist(str_split(xx_jobTitle, " "))
        xx_jobTitle <- xx_jobTitle[!(xx_jobTitle %in% stopWords)]
        xx_jobTitle <- xx_jobTitle[!(unlist(str_split(xx_jobTitle, " ")) %in% stopWords)]
        exp_job_class_title <- paste(xx_jobTitle, collapse = " ")
      }
    }
  }
  return(exp_job_class_title)
}


# Get specific required experience types (JOB_CLASS_FUNCTION)
get_jobClassFunction <- function(experience_requirement, pattern_spec_exp){
  if(length(grep("years of which", experience_requirement)) != 0){
    oneToTen <- "(one|two|three|four|five|six|seven|eight|nine|ten)"
    spec_exp_clause_start <- paste(oneToTen, "years of which")
    jobClassFn_length <- gsub(paste0("^.*", spec_exp_clause_start, ".*$"), "\\1", experience_requirement)
    xx_this_exp_req <- unlist(str_split(experience_requirement, spec_exp_clause_start))
    this_exp_req <- xx_this_exp_req[1]
    jobClassFn <- paste(xx_this_exp_req[-1], collapse = " ")
  }else{
    jobClassFn <- gsub(pattern_spec_exp, "\\1", experience_requirement)
    jobClassFn_length <- NA
  }
  return(c(jobClassFn, jobClassFn_length))
}


# Get required experience length (EXP_LENGTH)
get_expLength <- function(experience_requirement, pattern_num_before_exp){
  exp_length_writ <- gsub(pattern_num_before_exp, "\\1", experience_requirement, ignore.case = T)
  exp_length <- convert_writNum_to_digits(exp_length_writ)
  if(!is.na(exp_length)){
    if(nchar(exp_length) > 70){
      exp_length <- NA
    }else{
      # If experience length expressed in months, divide by 12
      exp_length <- as.numeric(exp_length)
      exp_length_units <- gsub(pattern_moYr_before_exp, "\\1", experience_requirement, ignore.case = T)
      if(exp_length_units == "months"){exp_length <- exp_length / 12}
    }
  }
  return(exp_length)
}










# Comprehensive salary info getter
get_salaries <- function(str_annSalary){
  str_annSalary <- gsub(", ", ",", str_annSalary) # WATER UTILITY SUPERINTENDENT
  str_annSalary <- gsub(" ,", ",", str_annSalary)
  str_annSalary <- gsub(",\\$", " \\$", str_annSalary)
  #--
  # Get all salary scales and/or flat-rated salaries from salary text
  annSalaries_raw <- removePunctuation(str_annSalary) # Remove all but numbers and "to" #\\(.*\\),;\\$
  salary_scales <- unlist(str_extract_all(annSalaries_raw, "[0-9]+ to [0-9]+")) # Keep only phrases of type "[some number] to [some number]"
  salaries_flat <- str_trim(gsub("[0-9]+ to [0-9]+|[a-zA-z]+", "", annSalaries_raw)) # Keep all except phrases of type "[some number] to [some number]"
  salaries_flat <- unlist(str_split(salaries_flat, " "))
  ind_rm <- which(salaries_flat == "")
  if(length(ind_rm) != 0){salaries_flat <- salaries_flat[-ind_rm]}
  #----------------------------------------------
  # The following snippet is needed to handle edge case "BOILERMAKER 3735 110714.txt"
  # which has a 5 figure salary expressed to 2 decimal places.
  # The snippet removes the 2 decimal places.
  if(!is.null(salaries_flat)){
    if(length(salaries_flat) != 0){
      if(nchar(salaries_flat) == 7){
        salaries_flat <- gsub(".{2}$", "", salaries_flat)
      }
    }
  }
  # The above snippet can be removed if all input files have salaries
  # rounded to nearest dollar (no decimal places).
  #----------------------------------------------
  # Number of flat rated salaries and salary scales
  #annSalaries_all <- as.numeric(annSalaries_all)
  n_salary_scales <- length(salary_scales)
  n_flat_rated_salaries <- length(salaries_flat)
  if(n_salary_scales + n_flat_rated_salaries > 0){
    # Deal with salary scales
    if(n_salary_scales > 0){
      ind_even <- 2 * n_salary_scales
      ind_odd <- 2 * n_salary_scales - 1
      salary_scale_bounds <- sapply(salary_scales, str_split, "to")
      salary_scale_bounds <- as.numeric(unlist(salary_scale_bounds))
      # Entry level salary
      entry_salaries_scale <- salary_scale_bounds[seq(1, ind_odd, 2)]
      out_entry_salaries_scale <- as.character(paste(entry_salaries_scale, collapse = ", "))
      mean_entry_salaries_scale <- mean(entry_salaries_scale)
      cv_entry_salaries_scale <- sd(entry_salaries_scale) / mean_entry_salaries_scale
      # Salary cap
      salary_caps <- salary_scale_bounds[seq(2, ind_even, 2)]
      out_salary_caps <- as.character(paste(salary_caps, collapse = ", "))
      mean_salary_caps <- mean(salary_caps)
      cv_salary_caps <- sd(salary_caps) / mean_salary_caps
      # Salary growth potential
      growth_potential <- diff(salary_scale_bounds)[seq(1, ind_odd, 2)]
      growth_potential_all <- paste(as.character(growth_potential), collapse = ", ")
      mean_growth_potential <- mean(growth_potential)
      cv_growth_potential <- sd(growth_potential) / mean_growth_potential
      min_growth_potential <- min(growth_potential, na.rm = T)
      max_growth_potential <- max(growth_potential, na.rm = T)
    }else{
      entry_salaries_scale <- NA
      out_entry_salaries_scale <- NA
      mean_entry_salaries_scale <- NA
      cv_entry_salaries_scale <- NA
      out_salary_caps <- NA
      mean_salary_caps <- NA
      cv_salary_caps <- NA
      growth_potential_all <- 0
      mean_growth_potential <- 0
      cv_growth_potential <- NA
      min_growth_potential <- 0
      max_growth_potential <- 0
    }
    # Deal with flat-rated salaries
    if(n_flat_rated_salaries > 0){
      out_entry_salaries_flat <- as.character(paste(salaries_flat, collapse = ", "))
      entry_salaries_flat <- as.numeric(salaries_flat)
      mean_entry_salaries_flat <- mean(entry_salaries_flat, na.rm = T)
      # min_entry_salaries_flat <- min(entry_salaries_flat, na.rm = T)
      # max_entry_salaries_flat <- max(entry_salaries_flat, na.rm = T)
      cv_entry_salaries_flat <- sd(entry_salaries_flat) / mean_entry_salaries_flat
    }else{
      entry_salaries_flat <- NA
      out_entry_salaries_flat <- NA
      mean_entry_salaries_flat <- NA
      cv_entry_salaries_flat <- NA
    }
    # Combine entry level salaries, flat-rated and scale based
    entry_salaries_all <- c(entry_salaries_flat, entry_salaries_scale)
    ind_rm <- which(is.na(entry_salaries_all))
    if(length(ind_rm) != 0){entry_salaries_all <- entry_salaries_all[-ind_rm]}
    mean_entry_salaries_all <- mean(entry_salaries_all, na.rm = T)
    min_entry_salaries_all <- min(entry_salaries_all, na.rm = T)
    max_entry_salaries_all <- max(entry_salaries_all, na.rm = T)
    cv_entry_salaries_all <- sd(entry_salaries_all, na.rm = T) / mean_entry_salaries_all
    out_entry_salaries_all <- as.character(paste(entry_salaries_all, collapse = ", "))
    min
    #----------------------------------------------
  }else{
    n_salary_scales <- NA
    n_flat_rated_salaries <- NA
    out_entry_salaries_scale <- NA
    out_salary_caps <- NA
    out_entry_salaries_flat <- NA
    out_entry_salaries_all <- NA
    mean_entry_salaries_all <- NA
    min_entry_salaries_all <- NA
    max_entry_salaries_all <- NA
    cv_entry_salaries_all <- NA
    mean_entry_salaries_scale <- NA
    cv_entry_salaries_scale <- NA
    salary_caps <- NA
    mean_salary_caps <- NA
    cv_salary_caps <- NA
    mean_entry_salaries_flat <- NA
    cv_entry_salaries_flat <- NA
    growth_potential_all <- NA
    mean_growth_potential <- NA
    cv_growth_potential <- NA
    min_growth_potential <- NA
    max_growth_potential <- NA
  }
  #----------------------------------------------
  df_salary_info <- data.frame(n_salary_scales, n_flat_rated_salaries,
                               ENTRY_SALARY = out_entry_salaries_all,
                               mean_entry_salaries_all,
                               min_entry_salaries_all,
                               max_entry_salaries_all,
                               cv_entry_salaries_all,
                               entry_salaries_scale = out_entry_salaries_scale, mean_entry_salaries_scale, cv_entry_salaries_scale,
                               entry_salaries_flat = out_entry_salaries_flat, mean_entry_salaries_flat, cv_entry_salaries_flat,
                               salary_caps = out_salary_caps, mean_salary_caps, cv_salary_caps,
                               growth_potential_all, mean_growth_potential, cv_growth_potential,
                               min_growth_potential, max_growth_potential)
  
  return(df_salary_info)
}

#======================================================
# DATA CLEANING
# 1) Compare job titles in file names with job titles found inside the file.
# Look for mislabeled or duplicate files.
file_path <- paste0(dir, "Job Bulletins/")
file_names <- list.files(file_path)
gsubPattern_in_fileName <- "[0-9\\._]|\\b[A-Z][a-z]+|[a-z]|\\s*\\([^\\)]+\\)|.txt|\\bREV\\b|REVISED|FINAL|\\bDRAFT\\b|TRACK CHANGES"
gsubPattern_in_txt <- "\\'|\\s*\\([^\\)]+\\)"
jobTitle_from_fileName <- c()
jobTitle_from_txt <- c()
for(i in 1:length(file_names)){
  file_name <- file_names[i]
  str <- gsub(gsubPattern_in_fileName, "", file_name)
  jobTitle_from_fileName[i] <- str_trim(str)
  #----------------
  bulletin_lines <- get_bulletinLines(file_name, file_path, quietly = T)
  jobTitle_from_txt[i] <- get_jobTitle_fromBulletin(bulletin_lines, gsubPattern_in_txt)
  
}

ind_dup <- which(duplicated(jobTitle_from_fileName))
duplicated_jobTitles_fileName <- jobTitle_from_fileName[ind_dup]
print(duplicated_jobTitles_fileName)
# So, there are two job titles that are found in more than one file name.
ind_dup <- which(duplicated(jobTitle_from_txt))
duplicated_jobTitles_txt <- jobTitle_from_txt[ind_dup]
print(duplicated_jobTitles_txt)
# So, there are five job titles that are found in more than one file. Two of these
# are the same ones we just saw repeated in the file names.
#
# Let's compare the duplicates' job titles as displayed in the file names vs.
# as displayed inside the files:
df_look <- data.frame(jobTitle_from_fileName, jobTitle_from_txt)
print(df_look[which(jobTitle_from_txt %in% duplicated_jobTitles_txt), ])
# There is a mismatch between job titles as found in the file names vs.
# as found inside the files for three jobs:
# "ANIMAL CARE TECHNICIAN SUPERVISOR"
# "SENIOR EXAMINER OF QUESTIONED DOCUMENTS"
# "WASTEWATER COLLECTION SUPERVISOR"
# Upon inspection of the file contents, it turns out that these are mislabeled
# duplicates of, respectively, the "WATER TREATMENT OFFICER", "WATER UTILITY SUPERINTENDENT",
# and "WASTEWATER TREATMENT OPERATOR" bulletins. Let's go ahead and delete these.
remove_these <- c("ANIMAL CARE TECHNICIAN SUPERVISOR",
                  "SENIOR EXAMINER OF QUESTIONED DOCUMENTS",
                  "WASTEWATER COLLECTION SUPERVISOR")
ind_rm <- which(jobTitle_from_fileName %in% remove_these)
file_names <- file_names[-ind_rm]
# 
# There are also two duplicates without a mismatch between the file name
# and file content versions of the job title:
# "CHIEF CLERK POLICE"
# "SENIOR UTILITY SERVICES SPECIALIST"
# Upon inspection of the bulletin folder, there are two versions of each 
# of these bulletins, one being more recent than the other.
# The job class number also differs between the two versions.
# We assume the host prefers to keep the more recent versions.
# To find out which is more recent we have to extract the opening dates.
ind_find <- grep("CHIEF CLERK POLICE|SENIOR UTILITY SERVICES SPECIALIST", file_names)
dup_files <- file_names[ind_find]
openDate_vec <- c()
for(i in 1:length(dup_files)){
  dupFile_name <- dup_files[i]
  bulletin_lines <- get_bulletinLines(dupFile_name, file_path, quietly = T)
  openDate_vec[i] <- get_openDate(bulletin_lines)
  
}
df_look <- data.frame(dup_file_name = dup_files, open_date = openDate_vec)
print(df_look)
# So, in both cases, there is a bulletin with a 2015 open date and one with 
# a 2018 open date. Assuming the more recent version is more valid, let's
# delete the 2015 versions.
dupFiles_old <- as.character(df_look$dup_file_name[c(1, 4)])
ind_rm <- which(file_names %in% dupFiles_old)
file_names <- file_names[-ind_rm]
# jobTitle_from_fileName <- jobTitle_from_fileName[-ind_rm]
# jobTitle_from_txt <- jobTitle_from_txt[-ind_rm]
#----------------------------------------------
# In the last two cases, there were issues with the job class number.
# This motivates a closer look at job class numbers in all bulletins.
#
# In analysis outside this kernel we found that the job class number
# occurs in the second line of most bulletins. However, there are several
# edge cases where it occurs in the first or third line, and sometimes it
# is repeated much farther down in the bulletin. We design our "get job 
# class number" function accordingly.
#
# Get job class numbers from all file names and file contents to check
# for duplicates and disagreement between number in file name and 
# number in contents.
jobClassNum_from_fileName <- c()
jobClassNum_from_txt <- c()
for(i in 1:length(file_names)){
  file_name <- file_names[i]
  #--------------
  jobClassNum_from_fileName[i] <- gsub(".*\\s(\\d{4})\\s.*", "\\1", file_name)
  #--------------
  bulletin_lines <- get_bulletinLines(file_name, file_path, quietly = T)
  jobClassNum_from_txt[i] <- get_jobClassNum_fromBulletin(bulletin_lines)
}
ind_dup <- which(duplicated(jobClassNum_from_fileName))
duplicated_jobClassNum_fileName <- jobClassNum_from_fileName[ind_dup]
print(duplicated_jobClassNum_fileName)
print(file_names[ind_dup])
# So, there is one job class number, "7260", that is duplicated in the
# file names. Let's see both of the files that have this job class number
# in their file name.
ind_look <- grep("7260", file_names)
df_look <- data.frame(file_name = file_names[ind_look],
                      jobClassNum_from_fileName = jobClassNum_from_fileName[ind_look],
                      jobClassNum_from_txt = jobClassNum_from_txt[ind_look])
print(df_look)
# The AIRPORT MANAGER job class number in its file name agrees with 
# its number in the file contents. Not so for the PRINCIPAL DEPUTY CONTROLLER.
# This suggests that the job class number found in the file name of the 
# PRINCIPAL DEPUTY CONTROLLER bulletin is incorrect. It should be the same
# as the number inside the file (9653).
#
# What about duplicate job class numbers inside the files?
ind_dup <- which(duplicated(jobClassNum_from_txt))
duplicated_jobClassNum_txt <- jobClassNum_from_txt[ind_dup]
print(duplicated_jobClassNum_txt)
print(file_names[ind_dup])
# So, there are no file contents with duplicate job class numbers.
#
# We assume from here on out that the job class number found in the bulletin
# is more valid than the one found in the file name. Hence no cleaning action
# is required here. Erroneous job class numbers in the file names will not
# affect our .csv file.
#
# Nonetheless, it might be of interest to the host to know how many instances of 
# disagreement there are between file name job class numbers and file content 
# job class numbers. So we pause to check:
test <- c()
for(i in 1:length(jobClassNum_from_txt)){
  test[i] <- identical(jobClassNum_from_txt[i], jobClassNum_from_fileName[i])
}
ind_disagree <- which(!test)
df_look <- data.frame(file_name = file_names[ind_disagree],
                      jobClassNum_from_fileName = jobClassNum_from_fileName[ind_disagree],
                      jobClassNum_from_txt = jobClassNum_from_txt[ind_disagree])
print(df_look)
# So, there are thirteen bulletins with disagreement between the file name
# and file content. We see here that in most of these cases this is because
# no job class number is reported in the file name.

# Our job class number getter function allows for NA output when no job
# class number is found. Are there any such instances?
ind_NA <- which(is.na(jobClassNum_from_txt))
print(file_names[ind_NA])
# Yes, the "Vocational Worker  DEPARTMENT OF PUBLIC WORKS.txt" bulletin
# has no job class number--neither in the file name nor in the file contents.
# Upon closer inspection, this bulletin is anomalous in other ways, particularly
# in its structure and salary information. It is too extreme a case for our
# code to accomodate, and so we will remove it.
special_case <- "Vocational Worker  DEPARTMENT OF PUBLIC WORKS.txt"
ind_rm <- which(file_names == special_case)
file_names <- file_names[-ind_rm]
length(file_names)

# 2) RETRIEVING SPECIFIC INFO FROM TEXT
n_reqs <- c()
n_subreqs <- c()
for(i in 1:length(file_names)){
  file_name <- file_names[i]
  print(file_name)
  bulletin_lines <- get_bulletinLines(file_name, file_path, quietly = T)
  section_headings <- get_sectionHeadings(bulletin_lines)
  str_reqMinquals <- get_sectionTxt(section_name = "REQUIREMENT",
                                    bulletin_lines,
                                    section_headings)
  n_reqs[i] <- str_count(str_reqMinquals, "\\b[0-9]\\.") + 1
  n_subreqs[i] <- str_count(str_reqMinquals, "\\b[a-z]\\.") + 1
}
hist(n_reqs)
length(which(n_reqs > 1))
hist(n_subreqs)
length(which(n_subreqs > 1))

file_names[which(n_reqs > 1)]
#which(file_names == "SUPPLY SERVICES MANAGER 1865 092818.txt")


# The host has requested retrieval of the following info from the job bulletins:
#"AIRPORT INFORMATION SPECIALIST 1783 121115.txt" Req'd job exp length expressed in hours 
file_names_subset <- file_names[which(n_subreqs > 1)]
stopWords <- stopwords("en")
list_df <- list()
pattern_num_before_exp <- "^.*(one|two|three|four|five|six|seven|eight|nine|ten)\\W(?:\\w+\\W+){1,6}?(full-time|full time|part-time|part time|experience)\\b.*$"
pattern_spec_exp <- "^.*?\\b[a-z]\\.(.*)$"
pattern_moYr_before_exp <- "^.*\\b(months|years)\\W+(?:\\w+\\W+){1,6}?(full-time|full time|part-time|part time|experience)\\b.*$"
pattern_fullPartTime_before_exp <- "^.*\\b(full-time|full time|part-time|part time)\\W+(?:\\w+\\W+){1,6}?experience\\b.*$"
pattern_jobTitle <- "^.*\\b(as a|as an|at the level of)\\W+(\\w+\\W+\\w+\\W+\\w+\\W+\\w+).*$"
pattern_jobTitle_trimPunct <- "(^.*)[,;\\.].*$"
oneToTen <- "(one|two|three|four|five|six|seven|eight|nine|ten)"
#for(i in 1:length(file_names)){
for(i in 1:length(file_names_subset)){
  #qq[i] <- 0
  #file_name <- file_names[i]
  file_name <- file_names_subset[i]
  print(file_name)
  bulletin_lines <- get_bulletinLines(file_name, file_path, quietly = T)
  section_headings <- get_sectionHeadings(bulletin_lines)
  str_reqMinquals <- get_sectionTxt(section_name = "REQUIREMENT",
                                    bulletin_lines,
                                    section_headings)
  #-------------------
  n_reqs <- str_count(str_reqMinquals, "\\b[0-9]\\.") + 1
  #-------------------
  # Split the requirements section into its numbered sections.
  req_vec <- unlist(strsplit(str_reqMinquals, "[0-9]\\."))
  ind_rm <- which(req_vec == "")
  if(length(ind_rm) != 0){req_vec <- req_vec[-ind_rm]}
  #===================================================
  # EXTRACT REQUIRED JOB EXPERIENCE INFO
  # (EXP_LENGTH, FULL_TIME_PART_TIME, EXP_JOB_CLASS_TITLE,
  # JOB_CLASS_FUNCTION)
  # Retain only the requirements having to do with job experience
  ind_jobExp <- grep("experience", req_vec)
  req_jobExp_vec <- req_vec[ind_jobExp]
  # Go through each job experience requirement and pull out req'd exp info
  if(length(ind_jobExp) != 0){
    exp_job_class_title_vec <- c()
    exp_length_vec <- c()
    full_time_part_time_vec <- c()
    jobClassFn_vec <- c()
    jobClassFn_length_vec <- c()
    for(j in 1:length(ind_jobExp)){
      this_jobExp_req <- req_jobExp_vec[j]
      #--------------------------------------------------
      # Required experience job title (EXP_JOB_CLASS_TITLE)
      exp_job_class_title_vec[j] <- get_expJobClassTitle(this_jobExp_req, pattern_jobTitle, pattern_jobTitle_trimPunct, stopWords)
      #--------------------------------------------------
      # Get required experience length (EXP_LENGTH)
      exp_length_vec[j] <- get_expLength(this_jobExp_req, pattern_num_before_exp)
      #--------------------------------------------------
      # Get full time or part time (FULL_TIME_PART_TIME)
      full_time_part_time <- gsub(pattern_fullPartTime_before_exp, "\\1", this_jobExp_req, ignore.case = T)
      if(nchar(full_time_part_time) > 50){full_time_part_time_vec[j] <- NA}else{full_time_part_time_vec[j] <- full_time_part_time}
      #--------------------------------------------------
      # Get specific types of required experience (JOB_CLASS_FUNCTION)
      n_subreqs <- str_count(this_jobExp_req, "\\b[a-z]\\.") + 1
      if(n_subreqs > 1){
        out <- get_jobClassFunction(this_jobExp_req, pattern_spec_exp)
        jobClassFn_vec[j] <- out[1]
        jobClassFn_length_vec[j] <- out[2]
      }else{
        jobClassFn_vec[j] <- NA
        jobClassFn_length_vec[j] <- NA
      }
      #--------------------------------------------------
      
    }
    
    nrows_out <- length(exp_length_vec)
    out_df_exp <- data.frame(FILE_NAME = rep(file_name, nrows_out),
                         EXP_LENGTH = exp_length_vec,
                         FULL_TIME_PART_TIME = full_time_part_time_vec,
                         EXP_JOB_CLASS_TITLE = exp_job_class_title_vec,
                         JOB_CLASS_FUNCTION = jobClassFn_vec,
                         job_class_function_length = jobClassFn_length_vec)
  }else{
    out_df_exp <- data.frame(FILE_NAME = file_name,
                         EXP_LENGTH = NA,
                         FULL_TIME_PART_TIME = NA,
                         EXP_JOB_CLASS_TITLE = NA,
                         JOB_CLASS_FUNCTION = NA,
                         job_class_function_length = NA)
  }
  #===================================================
  # EXTRACT REQUIRED EDUCATION
  # (COURSE_COUNT, COURSE_LENGTH, COURSE_SUBJECT, 
  # MISC_COURSE_DETAILS)
  ind_educ <- grep("graduation|degree|course", req_vec, ignore.case = T)
  
  if(length(ind_educ) != 0){
    req_educ_vec <- req_vec[ind_educ]
    
    
    #this_pattern <- "^.*\\b(particular phrase)\\W+((?:\\w+\\W+){3}\\w+).*$"  
    this_educ_req <- req_educ_vec[1]
    #pattern_subject <- "^.*\\b(degree in|,|or)\\W+((?:\\w+\\W+){2}\\w+)\\W+(,|or|).*$"
    pattern_subject <- "^.*\\b(degree in)\\W+(.*)\\W+(,|or).*$"
    gsub(pattern_subject, "\\2", this_educ_req)
    course_subjects[i] <- gsub(pattern_subject, "\\2", this_educ_req)
    
    this_pattern <- regexpr("(?<=particular phrase).*, or \\w+", this_txt, perl=TRUE)
    this_ext <- regmatches(this_txt, this_pattern)
    print(x)
    
  }
  
  # this_txt <- "Blah blah blah particular phrase this guy, this other guy, that guy, that other guy, or something else blah blah blah, blah blah. Blah blah blah, blah; and so blah."
  # this_pattern <- "^.*\\b(particular phrase)\\W+(.*)\\W+(,|or).*$"
  # gsub(this_pattern, "\\2", this_txt, ignore.case = T)
  
  #===================================================
  list_df_exp[[i]] <- out_df_exp
  
}

#length(which(qq == 1))

df_exp <- do.call(rbind, list_df)

for(i in 1:ncol(df_exp)){
  print(class(df_exp[, i]))
  if(class(df_exp[, i]) == "factor"){
    df_exp[, i] <- as.character(df_exp[, i])
  }
}

length(grep("part", df_exp$FULL_TIME_PART_TIME, ignore.case = T))


















































#file_name <- file_names[44]




parse_bulletin <- function(file_name, file_path){
  print(file_name)
  bulletin_lines <- get_bulletinLines(file_name, file_path, quietly = F)
  section_headings <- get_sectionHeadings(bulletin_lines)
  #---------------------------------------------
  # Job class title
  # job_class_title <- bulletin_lines[1]
  # job_class_title <- gsub("[0-9\\(\\)\\.txt]|REV|REVISED|[a-z]", "", file_name)
  # job_class_title <- str_trim(job_class_title)
  job_title <- get_jobTitle_fromBulletin(bulletin_lines, gsub_pattern = "\\'|\\s*\\([^\\)]+\\)")
  #---------------------------------------------
  # Job class number (taken from inside file)
  # job_class_no <- bulletin_lines[grep("Class code", bulletin_lines, ignore.case = T)[1]]
  # job_class_no <- gsub("[^0-9]", "", job_class_no)
  # if(nchar(job_class_no) > 4){job_class_no <- substr(job_class_no, 1, 4)} #"MARINE ENVIRONMENTAL SUPERVISOR" "SENIOR COMPUTER OPERATOR 1428 102017.bulletin_lines" "SUPERVISING CRIMINALIST 2235 030416.txt" 
  job_class_num <- get_jobClassNum_fromBulletin(bulletin_lines)
  #---------------------------------------------
  # Opening date
  # ind_openDate <- grep("Open Date", bulletin_lines, ignore.case = T)
  # xx <- bulletin_lines[ind_openDate[1]]
  # open_date <- gsub("\\b[^0-9-]", "", xx)
  # if(nchar(open_date) > 8){open_date <- substr(open_date, 5, 12)} #"MARINE ENVIRONMENTAL SUPERVISOR" "SENIOR COMPUTER OPERATOR 1428 102017.txt" "SUPERVISING CRIMINALIST 2235 030416.txt" 
  open_date <- get_openDate(bulletin_lines)
  #---------------------------------------------
  # Requirements
  str_reqMinquals <- get_sectionTxt(section_name = "REQUIREMENT",
                                    bulletin_lines,
                                    section_headings)
  #---------------------------------------------
  # Duties
  str_Duties <- get_sectionTxt(section_name = "DUTIES",
                               bulletin_lines,
                               section_headings)
  #---------------------------------------------
  # Process Notes
  str_procNotes <- get_sectionTxt(section_name = "PROCESS NOTES",
                                  bulletin_lines,
                                  section_headings)
  #---------------------------------------------
  # Selection Process
  str_selectProc <- get_sectionTxt(section_name = "SELECTION PROCESS",
                                   bulletin_lines,
                                   section_headings)
  #---------------------------------------------
  # Selective Certification
  str_selectCert <- get_sectionTxt(section_name = "SELECTIVE CERTIFICATION",
                                   bulletin_lines,
                                   section_headings)
  
  #--
  # REQUIREMENT SET ID
  #--
  # REQUIREMENT SUBSET ID
  #--
  # EDUCATION YEARS
  # grep("college|university", str_reqMinquals)
  # grep("degree in", str_reqMinquals)
  #--
  # SCHOOL TYPE
  #--
  # EDUCATION MAJOR
  #--
  # EXPERIENCE LENGTH
  #--
  # FULL TIME PART TIME
  #--
  # EXP JOB CLASS TITLE
  #--
  # EXP_JOB_CLASS_ALT_RESP
  #--
  # EXP_JOB_CLASS_FUNCTION
  #--
  # COURSE_COUNT
  #--
  # COURSE_LENGTH
  #--
  # COURSE_SUBJECT
  #--
  # MISC_COURSE_DETAILS
  #--
  # DRIVERS_LICENSE_REQ
  #--
  # DRIV_LIC_TYPE
  #--
  # ADDTL_LIC
  #--
  # EXAM_TYPE
  INT_DEPT_PROM <- ifelse(sum(str_detect(section_headings, "INTERDEPARTMENTAL PROMOTIONAL|INTERDEPARMENTAL PROMOTIONAL")) == 1, 1, 0)
  DEPT_PROM <- ifelse(sum(str_detect(section_headings, "DEPARTMENTAL PROMOTIONAL|DEPARMENTAL PROMOTIONAL")) == 1, 1, 0)
  OPEN <- ifelse(sum(str_detect(section_headings, "OPEN COMPETITIVE")) == 1, 1, 0)
  OPEN_INT_PROM <- ifelse(INT_DEPT_PROM == 1 & OPEN == 1, 1, 0)
  if(DEPT_PROM == 1){
    exam_type <- "DEPT_PROM"
  }else{
    if(OPEN_INT_PROM == 1){
      exam_type <- "OPEN_INT_PROM"
    }else{
      if(INT_DEPT_PROM == 1){exam_type <- "INT_DEPT_PROM"}
      if(OPEN == 1){exam_type <- "OPEN"}
    }
  }
  #--
  # Salary
  # Get salary text
  salary_section_identifier <- "ANNUAL SALARY|ANNUALSALARY"
  ind_annSalary_start <- grep(salary_section_identifier, bulletin_lines) + 1
  str_annSalary_end <- section_headings[grep(salary_section_identifier, section_headings) + 1]
  ind_annSalary_end <- grep(str_annSalary_end, bulletin_lines) - 1
  ind_rm <- which(ind_annSalary_end < ind_annSalary_start)
  if(length(ind_rm) != 0){ind_annSalary_end <- ind_annSalary_end[-ind_rm]}
  ind_annSalary_end <- ind_annSalary_end[1]
  str_annSalary <- bulletin_lines[ind_annSalary_start:ind_annSalary_end]
  str_annSalary <- paste(str_annSalary, collapse = " ")
  # Split into GEN and DWP salary text
  str_annSalary_vec <- unlist(str_split(str_annSalary, "Power"))
  str_annSalary_GEN <- str_annSalary_vec[1]
  str_annSalary_DWP <- str_annSalary_vec[2]
  if(is.na(str_annSalary_GEN)){str_annSalary_GEN <- NULL}
  if(is.na(str_annSalary_DWP)){str_annSalary_DWP <- NULL}
  #--
  # Get GEN salary info
  df_annSalary_GEN <- get_salaries(str_annSalary_GEN)
  colnames(df_annSalary_GEN) <- paste0(colnames(df_annSalary_GEN), "_GEN")
  # Get DWP salary info
  df_annSalary_DWP <- get_salaries(str_annSalary_DWP)
  colnames(df_annSalary_DWP) <- paste0(colnames(df_annSalary_DWP), "_DWP")
  #=============================================
  df_out <- data.frame(FILE_NAME = file_name,
                       JOB_CLASS_TITLE = job_title,
                       JOB_CLASS_NO = job_class_num,
                       Requirements = str_reqMinquals,
                       Duties = str_Duties,
                       Process_Notes = str_procNotes,
                       Selection_Process = str_selectProc,
                       Selection_Certification = str_selectCert,
                       EXAM_TYPE = exam_type,
                       OPEN_DATE = open_date)
  df_out <- as.data.frame(do.call(cbind, list(df_out, df_annSalary_GEN, df_annSalary_DWP)))
  return(df_out)
}
#===============================================
list_df <- map(file_names, parse_bulletin, file_path)

# list_df <- list()
# for(i in 1:length(file_names)){
#   file_name <- file_names[i]
#   list_df[[i]] <- parse_bulletin(file_name, file_path)
# }

df <- do.call(rbind, list_df)






for(i in 1:ncol(df)){
  print(class(df[, i]))
  if(class(df[, i]) == "factor"){
    df[, i] <- as.character(df[, i])
  }
}

class(df$Requirements)
df$Str <- paste(df$Duties, df$Requirements)
df$Str <- paste(df$Str, df$Process_Notes)
df$Str <- paste(df$Str, df$Selection_Process)
df$Str <- paste(df$Str, df$Selection_Certification)
#df$Str[145]
df$num_words <- str_count(df$Str, "\\w+")
nsent_vec <- c()
for(i in 1:nrow(df)){
  sents <- tokenize_sentences(df$Str[i])
  nsent_vec[i] <- length(unlist(sents))
}
df$num_sent <- nsent_vec



removeURL <- function(x) gsub("http:[[:alnum:]]*", "", x)
processCorpus <- function (corpus)
{
  corpus <- tm_map(corpus, content_transformer(removeURL))
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, removePunctuation, preserve_intra_word_dashes = TRUE)
  corpus <- tm_map(corpus, removeWords, stopwords("english"))
  corpus <- tm_map(corpus, stemDocument, language = "english")
  corpus <- tm_map(corpus, stripWhitespace)
  corpus <- tm_map(corpus, function (x) {
    gsub("\\s*(?<!\\B|-)\\d+(?!\\B|-)\\s*", "", x, perl = TRUE) })
  # corpus <- tm_map(corpus, function (x) {
  #   gsub("\\s[a-z]{1}\\s", "", x) })
  # corpus <- tm_map(corpus, stripWhitespace)
  corpus <- tm_map(corpus, str_trim)
  
  
  return (corpus)
}


#--------------------------------------
# Finding structure/clustering in the data, topics
#library(rJava)
#install.packages("RWeka")
# library(RWeka)
# bulletin_corpus <- VCorpus(VectorSource(df$Str))
# #summary(corpus)  #check what went in
# bulletin_corpus <- processCorpus(bulletin_corpus)
# 
# dtm <- DocumentTermMatrix(corpus) 
# dtm <- removeSparseTerms(dtm, 0.9)
# #Sys.setenv(JAVA_HOME="")
# TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 3))
# dtm_trigram <- TermDocumentMatrix(corpus, control = list(tokenize = TrigramTokenizer))
# dtm_trigram <- removeSparseTerms(dtm_trigram, 0.9)
# inspect(dtm_trigram[1:5,1:5])

bulletin_corpus <- Corpus(VectorSource(df$Str))
#summary(bulletin_corpus)  #check what went in
bulletin_corpus <- processCorpus(bulletin_corpus)
bulletin_corpus[[1]]$content

bulletin_corpus_file_path <- paste0(dir, "bulletin_corp.txt")
write.table(bulletin_corpus$content, bulletin_corpus_file_path)
word2phrase(train_file = bulletin_corpus_file_path, output_file = "bulletin_vec.txt")
df_bullcorp <- read.table("bulletin_vec.txt")
bulletin_corpus <- Corpus(VectorSource(df_bullcorp$x))
dtm <- DocumentTermMatrix(bulletin_corpus)
dtm <- removeSparseTerms(dtm, 0.9)
inspect(dtm[1:5, 1:5])

df_dtm <- tidy(dtm)
colnames(df_dtm)[1] <- "DOCUMENT"
df_dtm <- df_dtm %>% spread(term, count)
dim(df_dtm)
df_dtm[is.na(df_dtm)] <- 0
df_dtm$DOCUMENT <- df$JOB_CLASS_TITLE
in_mat <- as.matrix(df_dtm[, -1])
cormat <- cor(in_mat)
#image(cormat)

max_graph <- 10

e <- eigen(cormat)
eig_vectors <- e$vectors
lam_cor <- e$values
lamcor_max <- max(lam_cor)
N_t <- nrow(in_mat)
N_c <- ncol(in_mat)
Q <- N_t / N_c
s_sq <- 1 - lamcor_max / N_c
#s_sq <- 1
lamrand_max <- s_sq * (1 + 1 / Q + 2 / sqrt(Q))
lamrand_min <- s_sq * (1 + 1 / Q - 2 / sqrt(Q))
lam <- seq(lamrand_min, lamrand_max, 0.001)
dens_rand <- Q / (2 * pi * s_sq) * sqrt((lamrand_max - lam) * (lam - lamrand_min)) / lam
df_e <- data.frame(values = lam_cor)
#--
gg <- ggplot() +
  geom_density(data = df_e, aes(x = values, color = "Correlation Matrix")) +
  #geom_histogram(data = df_e, aes(x = values), alpha = 0.2) +
  geom_line(data = data.frame(x = lam, y = dens_rand), aes(x = x, y = y, color = "Random matrix")) +
  coord_cartesian(xlim = c(0, ceiling(lamcor_max))) +
  scale_colour_manual(name = "Eigenvalue density", 
                      values = c(`Correlation Matrix` = "blue", `Random matrix` = "orange"))
gg
#-----------------------------
# How many collective modes?
ind_deviating_from_noise <- which(lam_cor > lamrand_max)
collModes <- as.matrix(eig_vectors[, ind_deviating_from_noise])

noiseModes <- as.matrix(eig_vectors[, -ind_deviating_from_noise])
n_collModes <- ncol(collModes)
#-----------------------------
# Set sign of eigenvectors such that they
# best conform to the input time series
Modes <- in_mat %*% collModes
ts_avg <- in_mat %*% rep(1, N_c) * 1 / N_c
for(i in 1:n_collModes){
  sse <- sum((Modes[, i] - ts_avg)^2)
  sse_neg <- sum((-Modes[, i] - ts_avg)^2)
  sse_vec <- c(sse, sse_neg)
  if(which(sse_vec == min(sse_vec)) == 2){
    collModes[, i] <- -collModes[, i]
  }
}
#-----------------------------
n_collModes_really <- n_collModes
n_collModes_to_graph <- n_collModes
collModes_really <- collModes
print(paste("Number of collective modes: ", n_collModes))
if(ncol(collModes) > max_graph){
  collModes <- collModes[, 1:max_graph]
  n_collModes_to_graph <- max_graph
}
#-----------------------------

df_cmodes <- as.data.frame(collModes^2)
words <- colnames(df_dtm[-1])
this_mode <- df_cmodes$V2
q <- quantile(this_mode, probs = 0.95)
ind_top <- which(this_mode > as.numeric(q))
ind_top_ordered <- ind_top[order(this_mode[ind_top], decreasing = T)]
data.frame(highest = words[ind_top_ordered],
           score = this_mode[ind_top_ordered])



library(mclust)
# Model-based-clustering (takes a little bit -- Correctly chooses 9 as optimal number of clusters!)
#class(df_dtmTri)
mc <- Mclust(t(in_mat))
# Print a summary
summary(mc)

library(factoextra)
fviz_cluster(mc, frame.type = "norm", geom = "point")

df_mc <- data.frame(mcClust = mc$classification, Word = colnames(df_dtm)[-1])
df_mc[which(df_mc$mcClust == 1), ]
df_mc[which(df_mc$mcClust == 2), ]
df_mc$Word[which(df_mc$mcClust == 3)]
df_mc[which(df_mc$mcClust == 4), ]
df_mc[which(df_mc$mcClust == 5), ]
df_mc[which(df_mc$mcClust == 9), ]

# Contributions of items to each mode
df_plot <- as.data.frame(collModes^2)
gathercols <- colnames(df_plot)
df_plot$Word <- colnames(in_mat)
df_plot <- merge(df_plot, df_mc, by = "Word")
df_plot <- df_plot %>% gather_("Mode", "Contribution", gathercols)
df_plot <- subset(df_plot, Mode %in% c("V1", "V2", "V3", "V4"))
#df_plot <- subset(df_plot, Mode %in% c("V5", "V6", "V7", "V8"))
df_plot$mcClust <- as.factor(df_plot$mcClust)
xx <- df_plot$mcClust
df_plot$Word <- factor(df_plot$Word, levels = unique(df_plot$Word[order(xx)]))
gg <- ggplot(df_plot, aes(x = Word, y = Contribution, fill = mcClust))
gg <- gg + geom_bar(stat = "identity", position = "dodge")
#gg <- gg + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
gg <- gg +  facet_wrap(~ Mode, ncol = 1)
# gg <- gg + theme(axis.text.x = element_blank(),
#                  axis.title.x = element_blank())
gg <- gg + theme(axis.text.x = element_text(angle = 75, hjust = 1))
gg


ind <- which(collModes[, 1]^2 > 0.004)
colnames(in_mat)[ind]
#--------------------------------------



semantic_alignment <- function(txt_to_assess, df_wordVecs, list_semantic_poles){
  
  general_vocab <- df_wordVecs$Word
  bulletin_vocab <- unlist(str_split(txt_to_assess, " "))
  # ind_keep <- which(this_vocab %in% general_vocab)
  # this_vocab <- this_vocab[ind_keep]
  
  ind_bulletin_vocab <- which(general_vocab %in% bulletin_vocab)
  df_bulletin_vecs <- df_wordVecs[ind_bulletin_vocab, -1]
  bulletinVec <- colSums(df_bulletin_vecs) / (nrow(df_bulletin_vecs) - 1)
  
  pole_1_vec <- list_semantic_poles[[1]]
  pole_2_vec <- list_semantic_poles[[2]]
  
  semantic_alignment_pole_1 <- as.numeric(lsa::cosine(bulletinVec, pole_1_vec))
  semantic_alignment_pole_2 <- as.numeric(lsa::cosine(bulletinVec, pole_2_vec))
  
  semantic_score <- semantic_alignment_pole_1 - semantic_alignment_pole_2
  print(semantic_score)
  return(semantic_score)
  
}


get_average_wordVector <- function(this_semantic_pole, df_wordVecs){
  ind_these_wordVecs <- which(df_wordVecs$Word %in% this_semantic_pole)
  df_these_wordVecs <- df_wordVecs[ind_these_wordVecs, -1]
  average_semantic_vec <- colSums(df_these_wordVecs) / (nrow(df_these_wordVecs) - 1)
  
}





file_path <- paste0(dir, "COCA/")
COCA_corpus <- Corpus(DirSource(file_path))
COCA_corpus <- processCorpus(COCA_corpus)
#COCA_corpus[[1]]$content
length(COCA_corpus)
COCA_corpus_file_path <- paste0(dir, "COCA_corp.txt")
write.table(COCA_corpus$content, COCA_corpus_file_path, sep = "\t")
word2phrase(train_file = COCA_corpus_file_path, output_file = "COCA_vec.txt")
wordvec_length <- 200
# model <- word2vec(layer1_size = wordvec_length, train_file = COCA_corpus_file_path, output_file = "vec.bin", binary = 1, num_threads = 128)
model <- word2vec(layer1_size = wordvec_length, train_file = "COCA_vec.txt", output_file = "vec.bin", binary = 1, num_threads = 128)
#--
#--
# model <- word2vec(train_file = "vec.txt", output_file = "vec2.bin", binary = 1, num_threads = 128)
# dist = distance(file_name = "vec2.bin", search_word = c("man", "men", "male"), num = 10)
# dist
# vocab_count(file_name = COCA_corpus_file_path, vocab_file = "vocab.txt", min_count = 20)
# COCA_vocab <- read.table("vocab.txt")
# colnames(COCA_vocab) <- c("Word", "Freq")
# head(COCA_vocab)
#dist = distance(file_name = "vec.bin", search_word = "man", num = 10)
# dist

bin_to_txt("vec.bin", "vector.txt")
#df_wordvec = as.data.frame(read.table("vector.txt", skip = 1))
#library(readr)

df_wordVecs <- as.data.frame(read_delim("vector.txt", 
                                        skip = 1, delim = " ",
                                        col_names = c("Word", paste0("E", 1:wordvec_length))))
df_wordVecs <- df_wordVecs[-nrow(df_wordVecs), ]
global_vocab <- df_wordVecs$Word
length(global_vocab)
class(df_wordVecs$Word)
grep("white", global_vocab)
global_vocab[grep("hind", global_vocab)]
distance(file_name = "vec.bin", search_word = "india", num = 10)

feminine_semantic_pole <- c("feminin", "femal", "woman", "women", "communal", "inclus")
masculine_semantic_pole <- c("man", "men", "male", "domin", "exclus")
caucasian_semantic_pole <- c("white", "american")
african_american_semantic_pole <- c("african-american", "black", "american")
latino_semantic_pole <- c("hispan", "latin", "american")
asian_semantic_pole <- c("asian", "southeast", "chines", "american")

fem_semantic_vec <- get_average_wordVector(feminine_semantic_pole, df_wordVecs)
masc_semantic_vec <- get_average_wordVector(masculine_semantic_pole, df_wordVecs)
caucas_semantic_vec <- get_average_wordVector(caucasian_semantic_pole, df_wordVecs)
afAmer_semantic_vec <- get_average_wordVector(african_american_semantic_pole, df_wordVecs)
latino_semantic_vec <- get_average_wordVector(latino_semantic_pole, df_wordVecs)
asian_semantic_vec <- get_average_wordVector(asian_semantic_pole, df_wordVecs)

list_semantic_poles <- list(caucas_semantic_vec, latino_semantic_vec)

outlist <- map(bulletin_corpus$content, semantic_alignment, df_wordVecs, list_semantic_poles)
fem_semanticAlignment_score <- do.call(c, outlist)

hist(fem_semanticAlignment_score)

q <- quantile(fem_semanticAlignment_score, probs = 0.95)
ind_top <- which(fem_semanticAlignment_score > as.numeric(q))
ind_top_ordered <- ind_top[order(fem_semanticAlignment_score[ind_top], decreasing = T)]
data.frame(Jobs_with_highest_feminine_alignment = df$JOB_CLASS_TITLE[ind_top_ordered],
           Gender_score = fem_semanticAlignment_score[ind_top_ordered])

q <- quantile(-fem_semanticAlignment_score, probs = 0.95)
ind_bottom <- which(-fem_semanticAlignment_score > as.numeric(q))
ind_bottom_ordered <- ind_bottom[order(fem_semanticAlignment_score[ind_bottom], decreasing = F)]
data.frame(Jobs_with_highest_masculine_alignment = df$JOB_CLASS_TITLE[ind_bottom_ordered],
           Gender_score = fem_semanticAlignment_score[ind_bottom_ordered])

mean(df$min_entry_salaries_all_GEN[ind_top], na.rm = T)
mean(df$min_entry_salaries_all_GEN[ind_bottom], na.rm = T)

























#data.frame(df$JOB_CLASS_TITLE[1:10], file_names[1:10])
# nrow(df)
# length(file_names)


# df$lmean_entry_salaries_all_GEN <- log(df$mean_entry_salaries_all_GEN)
# df$lmean_entry_salaries_all_DWP <- log(df$mean_entry_salaries_all_DWP)
# df$lmin_entry_salaries_all_GEN <- log(df$min_entry_salaries_all_GEN)
# df$lmin_entry_salaries_all_DWP <- log(df$min_entry_salaries_all_DWP)
# df$lmax_entry_salaries_all_GEN <- log(df$max_entry_salaries_all_GEN)
# df$lmax_entry_salaries_all_DWP <- log(df$max_entry_salaries_all_DWP)
# 
# df$lmin_growth_potential_GEN <- log(df$mean_growth_potential_GEN)
# df$lmin_growth_potential_DWP <- log(df$mean_growth_potential_DWP)

df$lnum_words <- log(df$num_words)
df$lnum_sent <- log(df$num_sent)

# u <- df$lmean_growth_potential_GEN
# df$lmean_growth_potential_GEN[which(is.infinite(u))] <- NA
# u <- df$lmean_growth_potential_DWP
# df$lmean_growth_potential_DWP[which(is.infinite(u))] <- NA
# df$cv_entry_salaries_all_GEN


df$lmax_entry_salaries_all_DWPandGEN <- NA
df$lmin_entry_salaries_all_DWPandGEN <- NA
#df$lmean_growth_potential_DWPandGEN <- NA
df$lmax_growth_potential_DWPandGEN <- NA
df$lmin_growth_potential_DWPandGEN <- NA
for(i in 1:nrow(df)){
  df$lmin_growth_potential_DWPandGEN[i] <- log(min(df$min_growth_potential_DWP[i], df$min_growth_potential_GEN[i], na.rm = T))
  df$lmax_growth_potential_DWPandGEN[i] <- log(max(df$max_growth_potential_DWP[i], df$max_growth_potential_GEN[i], na.rm = T))
  
  df$lmax_entry_salaries_all_DWPandGEN[i] <- log(max(c(df$max_entry_salaries_all_DWP[i], df$max_entry_salaries_all_GEN[i]), na.rm = T))
  df$lmin_entry_salaries_all_DWPandGEN[i] <- log(min(c(df$min_entry_salaries_all_DWP[i], df$min_entry_salaries_all_GEN[i]), na.rm = T))
  df$lmean_growth_potential_DWPandGEN[i] <- log(mean(c(df$mean_growth_potential_DWP[i], df$mean_growth_potential_GEN[i]), na.rm = T))
}

u <- df$lmin_entry_salaries_all_DWPandGEN
df$lmin_entry_salaries_all_DWPandGEN[which(is.infinite(u))] <- NA
#u <- df$lmax_entry_salaries_all_DWPandGEN
#df$lmax_entry_salaries_all_DWPandGEN[which(is.infinite(u))] <- NA
u <- df$lmin_growth_potential_DWPandGEN
df$lmin_growth_potential_DWPandGEN[which(is.infinite(u))] <- NA
u <- df$lmax_growth_potential_DWPandGEN
df$lmax_growth_potential_DWPandGEN[which(is.infinite(u))] <- NA

df$fem_semAlign_score <- fem_semanticAlignment_score
df$lword_per_sent <- log(df$num_words / df$num_sent)

mod <- lm(fem_semAlign_score ~ lmax_entry_salaries_all_DWPandGEN +
            lmax_growth_potential_DWPandGEN +
            lnum_words + lnum_sent, df)
#lnum_words + lnum_sent, df)
summary(mod)  

mod <- lm(lmax_entry_salaries_all_DWPandGEN ~ fem_semAlign_score +
            lmax_growth_potential_DWPandGEN +
            lword_per_sent + lnum_sent, df)
#lnum_words + lnum_sent, df)
summary(mod)  




df_plot <- df[, c("JOB_CLASS_TITLE", "gender_score", "lmin_entry_salaries_all_DWPandGEN",
                  "lmax_growth_potential_DWPandGEN", "lword_per_sent")]
df_plot <- df_plot %>% gather(Type, Value, lmin_entry_salaries_all_DWPandGEN:lword_per_sent)
gg <- ggplot(df_plot, aes(x = gender_score, y = Value))
gg <- gg + geom_point()
gg <- gg + facet_wrap(~Type, ncol = 1, scales = "free")
gg


ind_look <- which(df$lmax_growth_potential_DWPandGEN < 9)
df$JOB_CLASS_TITLE[ind_look]


ind_outlier <- which(df$lmin_entry_salaries_all_DWPandGEN < 10)
df[ind_outlier, c("JOB_CLASS_TITLE", "ENTRY_SALARY_GEN", "ENTRY_SALARY_DWP")]
df <- df[-ind_outlier,]










file_path <- paste0(dir, "Job_Applicants_by_Gender_and_Ethnicity.csv")
df_div <- read.csv(file_path, stringsAsFactors = F)
nrow(df_div)
df_div$Job.Number <- gsub("(\\d{4}).*", "\\1", df_div$Job.Number)
df_div$Job.Number <- gsub("[A-Z][a-z]", "", df_div$Job.Number)
df_div$Job.Number <- str_trim(df_div$Job.Number)
df_log <- as.data.frame(apply(df_div[, 5:13], 2, log))
list_ind_inf <- apply(df_log, 2, function(x) which(is.infinite(x)))
# list_ind_nan <- apply(df_log, 2, function(x) which(is.nan(x)))
# list_ind_na <- apply(df_log, 2, function(x) which(is.na(x)))
for(i in 1:ncol(df_log)){
  df_log[list_ind_inf[[i]], i] <- 0
  # df_log[list_ind_nan[[i]], i] <- 0
  # df_log[list_ind_na[[i]], i] <- 0
}
colnames(df_log) <- paste0("l", colnames(df_div)[5:13])
df_div <- cbind(df_div, df_log)
colnames(df_div)[2] <- "JOB_CLASS_NO"
df_div <- merge(df_div, df, by = "JOB_CLASS_NO")
nrow(df_div)
ind_rm <- which(df_div$lmin_entry_salaries_all_DWPandGEN < 5)
df_div <- df_div[-ind_rm, ]
gg <- ggplot(df_div, aes(x = lMale, y = lmin_entry_salaries_all_DWPandGEN))
gg <- gg + geom_point()
gg



df_div$Asian2 <- as.numeric(df_div$Asian + df_div$Filipino)
df_div$lAsian2 <- log(df_div$Asian2)
u <- df_div$lAsian2
df_div$lAsian2[which(is.infinite(u))] <- 0



colnames(df_log)

mod <- lm(lmin_entry_salaries_all_DWPandGEN ~ lFemale +
            lMale, df_div)
summary(mod)


mod <- lm(lmin_entry_salaries_all_DWPandGEN ~ lBlack +
            lHispanic + lAsian2 + lCaucasian +
            lAmerican.Indian..Alaskan.Native, df_div)
summary(mod)

mod <- lm(lmax_growth_potential_DWPandGEN ~ lBlack +
            lHispanic + lAsian2 + lCaucasian +
            lAmerican.Indian..Alaskan.Native, df_div)
summary(mod)





model[1:3000,] %>% closest_to("woman", n = 30)

model[1:3000,] %>% cosineSimilarity(male_vec)









#prep_word2vec(origin = "corp.txt", destination = "corp2.txt", lowercase = F, bundle_ngrams = 3, force = T)
#x <- readLines("corp2.txt")
#model = train_word2vec(COCA_corpus_file_path, "corp_vectors.bin", vectors = 200, threads = 4, window = 12, iter = 5, negative_samples = 0, force = T)
#rm(corpus); gc()
#model = read.vectors("corp_vectors.bin")
#-------------------------------------------
#dimnames(model)[[1]] <- gsub("dash", "-", dimnames(model)[[1]])
# COCA_vocab <- dimnames(model)[[1]]
# COCA_vocab[80:110]
# COCA_vocab[grep("excel", COCA_vocab)]
# model[["king"]] - model[[c("man","men")]] + model[[c("woman","women")]]
# model[["male"]] - model[[c("domin","exclud")]] + model[[c("communal","inclus", "share", "collabor")]]
# feminine_gendered <- c("feminin", "femal", "woman", "women", "communal", "includ")
# masculine_gendered <- c("man", "men", "male", "exclud", "domin")
# cosineSimilarity(model[[c(feminine_gendered, masculine_gendered), average = F]], model[[c(feminine_gendered, masculine_gendered), average = F]])
#cosineSimilarity(model[[c("caucasian", "white", "black", "ethnic", "latin", "asian"), average = F]], model[[c("caucasian", "white", "black", "ethnic", "latin", "asian"), average = F]])
#as.numeric(model[["feminin"]])
# fem_vec <- as.numeric(model[[feminine_gendered]])
# mascul_vec <- as.numeric(model[[masculine_gendered]])

# fem_vec %*% masc_vec




gender_score_vec <- c()
caucas_score_vec <- c()
for(i in 1:nrow(df)){
  #print(i)
  #this_vocab <- unlist(str_split(bulletin_corpus$content[i], " "))  # or bulletin_corpus[[i]]$content
  #ind_keep <- which(this_vocab %in% COCA_vocab)
  #ind_keep <- which(this_vocab %in% COCA_vocab$Word)
  #ind_keep <- which(this_vocab %in% df_wordVecs$Word)
  
  # fem_alignment <- as.numeric(lsa::cosine(bulletinVec, fem_vec))
  # masc_alignment <- as.numeric(lsa::cosine(bulletinVec, masc_vec))
  
  # feminin_aligned <- cosineSimilarity(model[[this_vocab]], model[[feminine_gendered]])
  # masculin_aligned <- cosineSimilarity(model[[this_vocab]], model[[masculine_gendered]])
  # gender_score <- feminin_aligned - masculin_aligned
  # caucas_score <- cosineSimilarity(model[[this_vocab]], model[[c("white", "caucasian")]])
  # print(gender_score)
  # gender_score_vec[i] <- gender_score
  # caucas_score_vec[i] <- caucas_score
  
  # feminin_aligned <- c()
  # masculin_aligned <- c()
  # caucas_aligned <- c()
  # for(j in 1:length(this_vocab)){
  #   this_word <- this_vocab[j]
  #   feminin_aligned[j] <- cosineSimilarity(model[[this_word]], model[[feminine_gendered]])
  #   masculin_aligned[j] <- cosineSimilarity(model[[this_word]], model[[masculine_gendered]])
  #   caucas_aligned[j] <- cosineSimilarity(model[[this_word]], model[[c("white", "caucasian")]])
  #   
  # }
  # ind_nan <- which(is.nan(feminin_aligned))
  # if(length(ind_nan) != 0){
  #   g_aligned <- feminin_aligned[-ind_nan] - masculin_aligned[-ind_nan]
  #   caucas_aligned <- caucas_aligned[-ind_nan]
  # }else{
  #   g_aligned <- feminin_aligned - masculin_aligned
  # }
  # g_score <- mean(g_aligned)
  # cauc_score <- mean(caucas_aligned)
  # print(g_score)
  # print(cauc_score)
  # gender_score[i] <- g_score
  # caucas_score[i] <- cauc_score
}
